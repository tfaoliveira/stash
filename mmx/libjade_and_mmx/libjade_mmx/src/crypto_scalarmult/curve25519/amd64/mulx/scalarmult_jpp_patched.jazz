inline fn __load4(reg u64 p) -> reg u64[4]
{
  inline int i;
  reg u64[4] a;

  for i=0 to 4
  { a[i] = [p + 8*i]; }

  return a;
}

inline fn __store4(reg u64 p, reg u64[4] a)
{
  inline int i;

  for i=0 to 4
  { [p + 8*i] = a[i]; }
}

inline fn __ith_bit(stack u8[32] k, reg u64 ctr) -> reg u64
{
  reg u64 p bit;

  p = ctr;
  p >>= 3;
  bit = (64u) k[(int) p];

  p = ctr;
  p &= 7;
  bit >>= (p & 63);

  bit &= 1;

  return bit;
}


inline fn __next_bit(stack u64 k) -> reg u64, stack u64
{
  reg bool cf;
  reg u64 b one;

  ?{}, b = #set0();
  one = 1;
  _, cf, _, _, _, k = #SHL(k, 1);
  b = one if cf;
  return b, k;
}
inline fn __decode_scalar(reg u64[4] k) -> stack u8[32]
{
  inline int i;
  stack u8[32] ks;

  for i=0 to 4
  { ks[u64 i] = k[i]; }

  ks[0]  &= 0xf8;
  ks[31] &= 0x7f;
  ks[31] |= 0x40;

  return ks;
}

inline fn __decode_scalar_shl1(reg u64[4] k) -> stack u64[4]
{
  stack u64[4] ks;

  k[3] <<= 1;
  k[0] &= 0xfffffffffffffff8;
  k[3] |= 0x8000000000000000;

  ks = #copy(k);

  return ks;
}


inline fn __decode_u_coordinate4(reg u64[4] u) -> reg u64[4]
{
  u[3] &= 0x7fffffffffffffff;
  return u;
}

inline fn __decode_u_coordinate_base4() -> reg u64[4]
{
  reg u64[4] u;

  u[0] = 9;
  u[1] = 0;
  u[2] = 0;
  u[3] = 0;

  return u;
}

inline fn __init_points4(
  reg u64[4] initr)
  ->
  #mmx reg u64[4],
  reg      u64[4],
  stack    u64[4],
  stack    u64[4]
{
  inline int i;
  #mmx reg u64[4] x2;
  stack u64[4] x3 z3;
  reg u64[4] z2r;
  reg u64 z one;

  ?{}, z = #set0();
  one = 1;

  x2[0] = one;
  z2r[0] = z;
  x3 = #copy(initr);
  z3[0] = one;

  for i=1 to 4
  { x2[i] = z;
    z2r[i] = z;
    z3[i] = z;
  }

  //     (1,   0, init, 1)
  return x2, z2r, x3,  z3;
}

inline fn __init_points4_x3()
  ->
  stack u64[4],
  reg   u64[4],
  stack u64[4]
{
  inline int i;
  stack u64[4] f1s f3s;
  reg   u64[4] f2;
  reg   u64 z;

  ?{}, z = #set0();

  f1s[0] = 1;
  f2[0]  = 1;
  f3s[0] = 1;

  for i=1 to 4
  { f1s[i] = z;
    f2[i]  = z;
    f3s[i] = z;
  }

  return f1s, f2, f3s;
}

// h = f + g
// h = 2**0*f0 + 2**64*f1 + 2**128*f2 + 2**192*f3 +
//     2**0*g0 + 2**64*g1 + 2**128*g2 + 2**192*g3

inline fn __add4_rrs(reg u64[4] f, stack u64[4] g) -> reg u64[4]
{
  inline int i;
  reg bool cf;
  reg u64[4] h;
  reg u64 z;

  ?{}, z = #set0();

  h = #copy(f);

  cf, h[0] += g[0];
  for i=1 to 4
  { cf, h[i] += g[i] + cf; }

  _, z -= z - cf;
  z &= 38;

  cf, h[0] += z;
  for i=1 to 4
  { cf, h[i] += 0 + cf; }

  _, z -= z - cf;
  z &= 38;
  h[0] += z;

  return h;
}

inline fn __add4_xrx(reg u64[4] f, #mmx reg u64[4] g) -> #mmx reg u64[4]
{
  inline int i;
  reg bool cf;
  reg u64[4] h;
  #mmx reg u64[4] hs;
  reg u64 z;

  ?{}, z = #set0();

  h = #copy(g);

  cf, h[0] += f[0];
  for i=1 to 4
  { cf, h[i] += f[i] + cf; }

  _, z -= z - cf;
  z &= 38;

  cf, h[0] += z;
  for i=1 to 4
  { cf, h[i] += 0 + cf;
    hs[i] = h[i]; }

  _, z -= z - cf;
  z &= 38;
  h[0] += z;
  hs[0] = h[0];

  return hs;
}

inline fn __add4_sss(stack u64[4] fs gs) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h f;

  f = #copy(fs);
  h = __add4_rrs(f, gs);
  hs = #copy(h);

  return hs;
}

inline fn __add4_ssr(stack u64[4] fs, reg u64[4] g) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h;

  h = __add4_rrs(g, fs);
  hs = #copy(h);

  return hs;
}

inline fn __add4_xxr(#mmx reg u64[4] fs, reg u64[4] g) -> #mmx reg u64[4]
{
  #mmx reg u64[4] hs;

  hs = __add4_xrx(g, fs);

  return hs;
}

inline fn __add4_rsr(stack u64[4] fs, reg u64[4] g) -> reg u64[4]
{
  reg u64[4] h;

  h = __add4_rrs(g, fs);

  return h;
}

// h = f - g
// h = (2**0*f0 + 2**64*f1 + 2**128*f2 + 2**192*f3) -
//     (2**0*g0 + 2**64*g1 + 2**128*g2 + 2**192*g3)

inline fn __sub4_rrs(reg u64[4] f, stack u64[4] gs) -> reg u64[4]
{
  inline int i;
  reg bool cf;
  reg u64[4] h;
  reg u64 z;

  ?{}, z = #set0();

  h = #copy(f);

  cf, h[0] -= gs[0];
  for i=1 to 4
  { cf, h[i] -= gs[i] - cf; }

  _, z -= z - cf;
  z &= 38;

  cf, h[0] -= z;
  for i=1 to 4
  { cf, h[i] -= 0 - cf; }

  _, z -= z - cf;
  z &= 38;
  h[0] -= z;

  return h;
}

inline fn __sub4_sss(stack u64[4] fs gs) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h f;

  f = #copy(fs);
  h = __sub4_rrs(f, gs);
  hs = #copy(h);

  return hs;
}

inline fn __sub4_rss(stack u64[4] fs gs) -> reg u64[4]
{
  stack u64[4] hs;
  reg u64[4] h f;

  f = #copy(fs);
  h = __sub4_rrs(f, gs);

  return h;
}

inline fn __sub4_rsr(stack u64[4] fs, reg u64[4] g) -> reg u64[4]
{
  inline int i;
  reg bool cf;
  reg u64[4] h;
  reg u64 z;

  ?{}, z = #set0();

  h = #copy(fs);

  cf, h[0] -= g[0];
  for i=1 to 4
  { cf, h[i] -= g[i] - cf; }

  _, z -= z - cf;
  z &= 38;

  cf, h[0] -= z;
  for i=1 to 4
  { cf, h[i] -= 0 - cf; }

  _, z -= z - cf;
  z &= 38;
  h[0] -= z;

  return h;
}

inline fn __sub4_rxr(#mmx reg u64[4] fs, reg u64[4] g) -> reg u64[4]
{
  inline int i;
  reg bool cf;
  reg u64[4] h;
  reg u64 z;

  ?{}, z = #set0();

  h = #copy(fs);

  cf, h[0] -= g[0];
  for i=1 to 4
  { cf, h[i] -= g[i] - cf; }

  _, z -= z - cf;
  z &= 38;

  cf, h[0] -= z;
  for i=1 to 4
  { cf, h[i] -= 0 - cf; }

  _, z -= z - cf;
  z &= 38;
  h[0] -= z;

  return h;
}


inline fn __sub4_ssr(stack u64[4] fs, reg u64[4] g) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h;

  h = __sub4_rsr(fs, g);
  hs = #copy(h);

  return hs;
}

inline fn __sub4_sxr(#mmx reg u64[4] fs, reg u64[4] g) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h;

  h = __sub4_rxr(fs, g);
  hs = #copy(h);

  return hs;
}


inline fn __cswap4(
  stack u64[4] x2,
  reg   u64[4] z2r,
  stack u64[4] x3,
  stack u64[4] z3,
  reg   u64    toswap)
  ->
  stack u64[4],
  reg   u64[4],
  stack u64[4],
  stack u64[4]
{
  inline int i;
  reg u64[4] t4 x2r x3r z3r;
  reg u64 t mask;

  ?{}, mask = #set0();
  mask -= toswap; // if toswap == 1 mask = -1 or all bits at 1, 0 otherwise

  // swap between z2 and z3
  z3r = #copy(z3);
  t4  = #copy(z2r);

  for i=0 to 4 { t4[i]  ^= z3r[i]; } // t4 =  z2 ^ z3
  for i=0 to 4 { t4[i]  &= mask;   } // t4 = (z2 ^ z3) & mask --> if m==0 then t4 = {0}
  for i=0 to 4 { z2r[i] ^= t4[i];
                 z3r[i] ^= t4[i];
                 z3[i]   = z3r[i]; }

  // swap between x3r and z3
  x3r = #copy(x3);

  for i=0 to 4 { x2r[i]  = x2[i];
                 t       = x3r[i];
                 t      ^= x2r[i];
                 t      &= mask;
                 x2r[i] ^= t;
                 x3r[i] ^= t;
                 x2[i]   = x2r[i];
                 x3[i]   = x3r[i]; }

  return x2, z2r, x3, z3;
}

inline fn __cswap4_xrss(
  #mmx reg u64[4] x2,
  reg      u64[4] z2r,
  stack    u64[4] x3,
  stack    u64[4] z3,
  reg      u64    toswap)
  ->
  #mmx reg u64[4],
  reg      u64[4],
  stack    u64[4],
  stack    u64[4]
{
  inline int i;
  reg u64[4] t4 x2r x3r z3r;
  reg u64 t mask;

  ?{}, mask = #set0();
  mask -= toswap; // if toswap == 1 mask = -1 or all bits at 1, 0 otherwise

  // swap between z2 and z3
  z3r = #copy(z3);
  t4  = #copy(z2r);

  for i=0 to 4 { t4[i]  ^= z3r[i]; } // t4 =  z2 ^ z3
  for i=0 to 4 { t4[i]  &= mask;   } // t4 = (z2 ^ z3) & mask --> if m==0 then t4 = {0}
  for i=0 to 4 { z2r[i] ^= t4[i];
                 z3r[i] ^= t4[i];
                 z3[i]   = z3r[i]; }

  // swap between x3r and z3
  x3r = #copy(x3);

  for i=0 to 4 { x2r[i]  = x2[i];
                 t       = x3r[i];
                 t      ^= x2r[i];
                 t      &= mask;
                 x2r[i] ^= t;
                 x3r[i] ^= t;
                 x2[i]   = x2r[i];
                 x3[i]   = x3r[i]; }

  return x2, z2r, x3, z3;
}


inline fn __cswap4_ssss(
  stack u64[4] xs,
  stack u64[4] ys,
  reg   u64    swap)
  ->
  stack u64[4],
  stack u64[4]
{
  inline int i;
  reg u64[4] x y;
  reg u64 t mask;

  x = #copy(xs);

  mask = 0;
  mask -= swap;

  for i=0 to 4
  {
    y[i] = ys[i];

    t  = x[i];
    t ^= y[i];
    t &= mask;

    x[i] ^= t; // ^ (x[i] ^ y[i]) if swap == 1
    y[i] ^= t;

    ys[i] = y[i];
  }

  xs = #copy(x);

  return xs, ys;
}

inline fn __cswap4_rsrs(
  reg   u64[4] x,
  stack u64[4] ys,
  reg   u64    swap)
  ->
  reg   u64[4],
  stack u64[4]
{
  inline int i;
  reg u64[4] y;
  reg u64 t mask;

  mask = 0;
  mask -= swap;

  for i=0 to 4
  {
    y[i] = ys[i];

    t  = x[i];
    t ^= y[i];
    t &= mask;

    x[i] ^= t; // ^ (x[i] ^ y[i]) if swap == 1
    y[i] ^= t;

    ys[i] = y[i];
  }

  return x, ys;
}

inline fn __tobytes4(reg u64[4] f) -> reg u64[4]
{
  reg bool cf;
  reg u64 t;

  t = #LEA(f[3] + f[3]);
  ?{}, f[3] = #SAR(f[3], 63);
  t >>= 1;
  f[3] &= 19;
  f[3] += 19;

  cf, f[0] += f[3];
  cf, f[1] += 0 + cf;
  cf, f[2] += 0 + cf;
   _, t    += 0 + cf;

  f[3] = #LEA(t + t);
  ?{}, t = #SAR(t, 63);
  f[3] >>= 1;
  t = !t;
  t &= 19;

  cf, f[0] -= t;
  cf, f[1] -= 0 - cf;
  cf, f[2] -= 0 - cf;
   _, f[3] -= 0 - cf;

  return f;

}

inline fn __reduce4
( reg u64[4] h,
  reg u64[4] r,
  reg u64 _38,
  reg u64 z, // zero
  reg bool cf of // cf = 0 and of = 0
) -> reg u64[4]
{
  inline int i;
  reg u64 hi lo;

  //
  ( hi, lo )   = #MULX ( _38,  r[0] );
  of, h[0]     = #ADOX ( h[0], lo, of );
  cf, h[1]     = #ADCX ( h[1], hi, cf );

  ( hi, lo )   = #MULX ( _38,  r[1] );
  of, h[1]     = #ADOX ( h[1], lo, of );
  cf, h[2]     = #ADCX ( h[2], hi, cf );

  ( hi, lo )   = #MULX ( _38,  r[2] );
  of, h[2]     = #ADOX ( h[2], lo, of );
  cf, h[3]     = #ADCX ( h[3], hi, cf );

  ( r[0], lo ) = #MULX ( _38, r[3] );
  of, h[3]     = #ADOX ( h[3], lo, of );

  cf, r[0]     = #ADCX ( r[0], z, cf ); 
  of, r[0]     = #ADOX ( r[0], z, of );

  //
  _,_,_,_,_,lo = #IMULri ( r[0], 38 );

  cf, h[0] += lo;
  cf, h[1] += z + cf;
  cf, h[2] += z + cf;
  cf, h[3] += z + cf;

  // h[0] += (z - cf) & 38;
  _, z -= z - cf; // if cf = 1 then z = 0xFF..FF else z = 0
  z &= 38; // if cf = 1 then z = 38 else z = 0
  h[0] += z; // 

  return h;
}


inline fn __mul4_c0
( reg u64    f0,
  reg u64[4] g,
  reg u64    z, // zero
  reg bool   cf of // cf = 0 and of = 0
  ) ->
  reg u64[4],
  reg u64[4],
  reg bool,
  reg bool
{
  inline int i;
  reg u64 hi lo;
  reg u64[4] h r;

  (h[1], h[0]) = #MULX ( f0, g[0] );

  ( h[2], lo ) = #MULX ( f0, g[1] );
    cf, h[1]   = #ADCX ( h[1], lo, cf );

  ( h[3], lo ) = #MULX ( f0, g[2] );
    cf, h[2]   = #ADCX ( h[2], lo, cf );

  ( r[0], lo ) = #MULX ( f0, g[3] );
    cf, h[3]   = #ADCX ( h[3], lo, cf );

  cf, r[0] = #ADCX ( r[0], z, cf ); // cf = 0

  return h, r, cf, of;
}

inline fn __mul4_c1
( reg u64[4] h,
  reg u64[4] r,
  reg u64    f,
  reg u64[4] g,
  reg u64    z, // zero
  reg bool   cf of // cf = 0 and of = 0
  ) ->
  reg u64[4],
  reg u64[4],
  reg bool,
  reg bool
{
  inline int i;
  reg u64 hi lo;

  ( hi, lo )   = #MULX ( f, g[0] );
  of, h[1]     = #ADOX ( h[1], lo, of );
  cf, h[2]     = #ADCX ( h[2], hi, cf );

  ( hi, lo )   = #MULX ( f, g[1] );
  of, h[2]     = #ADOX ( h[2], lo, of );
  cf, h[3]     = #ADCX ( h[3], hi, cf );

  ( hi, lo )   = #MULX ( f, g[2] );
  of, h[3]     = #ADOX ( h[3], lo, of );
  cf, r[0]     = #ADCX ( r[0], hi, cf );

  ( r[1], lo ) = #MULX ( f, g[3] );
  of, r[0]     = #ADOX ( r[0], lo, of);

  cf, r[1]     = #ADCX ( r[1], z, cf);
  of, r[1]     = #ADOX ( r[1], z, of);

  return h, r, cf, of;
}

inline fn __mul4_c2
( reg u64[4] h,
  reg u64[4] r,
  reg u64    f,
  reg u64[4] g,
  reg u64    z, // zero
  reg bool   cf of // cf = 0 and of = 0
  ) ->
  reg u64[4],
  reg u64[4],
  reg bool,
  reg bool
{
  inline int i;
  reg u64 hi lo;

  ( hi, lo )   = #MULX ( f, g[0] );
  of, h[2]     = #ADOX ( h[2], lo, of );
  cf, h[3]     = #ADCX ( h[3], hi, cf );

  ( hi, lo )   = #MULX ( f, g[1] );
  of, h[3]     = #ADOX ( h[3], lo, of );
  cf, r[0]     = #ADCX ( r[0], hi, cf );

  ( hi, lo )   = #MULX ( f, g[2] );
  of, r[0]     = #ADOX ( r[0], lo, of );
  cf, r[1]     = #ADCX ( r[1], hi, cf );

  ( r[2], lo ) = #MULX ( f, g[3] );
  of, r[1]     = #ADOX ( r[1], lo, of);

  cf, r[2]     = #ADCX ( r[2], z, cf);
  of, r[2]     = #ADOX ( r[2], z, of);

  return h, r, cf, of;
}

inline fn __mul4_c3
( reg u64[4] h,
  reg u64[4] r,
  reg u64    f,
  reg u64[4] g,
  reg u64    z, // zero
  reg bool   cf of // cf = 0 and of = 0
  ) ->
  reg u64[4],
  reg u64[4],
  reg bool,
  reg bool
{
  inline int i;
  reg u64 hi lo;

  ( hi, lo )   = #MULX ( f, g[0] );
  of, h[3]     = #ADOX ( h[3], lo, of );
  cf, r[0]     = #ADCX ( r[0], hi, cf );

  ( hi, lo )   = #MULX ( f, g[1] );
  of, r[0]     = #ADOX ( r[0], lo, of );
  cf, r[1]     = #ADCX ( r[1], hi, cf );

  ( hi, lo )   = #MULX ( f, g[2] );
  of, r[1]     = #ADOX ( r[1], lo, of );
  cf, r[2]     = #ADCX ( r[2], hi, cf );

  ( r[3], lo ) = #MULX ( f, g[3] );
  of, r[2]     = #ADOX ( r[2], lo, of);

  cf, r[3]     = #ADCX ( r[3], z, cf);
  of, r[3]     = #ADOX ( r[3], z, of);

  return h, r, cf, of;
}

inline fn __mul4_rsr(stack u64[4] fs, reg u64[4] g) -> reg u64[4]
{
  reg bool cf of;
  reg u64[4] h r;
  reg u64 _38 f z;

  of, cf, _, _, _, z = #set0();

  f = fs[0];
  h, r, cf, of = __mul4_c0(      f, g, z, cf, of);

  f = fs[1];
  h, r, cf, of = __mul4_c1(h, r, f, g, z, cf, of);

  f = fs[2];
  h, r, cf, of = __mul4_c2(h, r, f, g, z, cf, of);

  f = fs[3];
  h, r, cf, of = __mul4_c3(h, r, f, g, z, cf, of);

  _38 = 38;
  h = __reduce4(h, r, _38, z, cf, of);

  return h;
}

inline fn __mul4_rxr(#mmx reg u64[4] fs, reg u64[4] g) -> reg u64[4]
{
  reg bool cf of;
  reg u64[4] h r;
  reg u64 _38 f z;

  of, cf, _, _, _, z = #set0();

  f = fs[0];
  h, r, cf, of = __mul4_c0(      f, g, z, cf, of);

  f = fs[1];
  h, r, cf, of = __mul4_c1(h, r, f, g, z, cf, of);

  f = fs[2];
  h, r, cf, of = __mul4_c2(h, r, f, g, z, cf, of);

  f = fs[3];
  h, r, cf, of = __mul4_c3(h, r, f, g, z, cf, of);

  _38 = 38;
  h = __reduce4(h, r, _38, z, cf, of);

  return h;
}


inline fn __mul4_rpr(reg ptr u64[4] fp, reg u64[4] g) -> reg u64[4]
{
  reg bool cf of;
  reg u64[4] h r;
  reg u64 _38 f z;

  of, cf, _, _, _, z = #set0();

  f = fp[0];
  h, r, cf, of = __mul4_c0(      f, g, z, cf, of);

  f = fp[1];
  h, r, cf, of = __mul4_c1(h, r, f, g, z, cf, of);

  f = fp[2];
  h, r, cf, of = __mul4_c2(h, r, f, g, z, cf, of);

  f = fp[3];
  h, r, cf, of = __mul4_c3(h, r, f, g, z, cf, of);

  _38 = 38;
  h = __reduce4(h, r, _38, z, cf, of);

  return h;
}

fn _mul4_rpr(reg ptr u64[4] fp, reg u64[4] g) -> reg u64[4]
{
  reg u64[4] h;

  h = __mul4_rpr(fp, g);

  return h;
}

inline fn _mul4_rsr_(stack u64[4] _fs, reg u64[4] _g) -> reg u64[4]
{
  reg ptr u64[4] fp;
  reg u64[4] _h h g;

  fp = _fs;
  g = #copy(_g);
  h = _mul4_rpr(fp, g);
  _h = #copy(h);

  return _h;
}

inline fn __mul4_ssr(stack u64[4] fs, reg u64[4] g) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h;

  h = __mul4_rsr(fs, g);
  hs = #copy(h);

  return hs;
}

inline fn __mul4_xsr(stack u64[4] fs, reg u64[4] g) -> #mmx reg u64[4]
{
  #mmx reg u64[4] hs;
  reg u64[4] h;

  h = __mul4_rsr(fs, g);
  hs = #copy(h);

  return hs;
}

inline fn __mul4_sss(stack u64[4] fs gs) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h g;

  g = #copy(gs);
  h = __mul4_rsr(fs, g);
  hs = #copy(h);

  return hs;
}

inline fn __mul4_sxs(#mmx reg u64[4] fs, stack u64[4] gs) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h g;

  g = #copy(gs);
  h = __mul4_rxr(fs, g);
  hs = #copy(h);

  return hs;
}

inline fn __mul4_rss(stack u64[4] fs gs) -> reg u64[4]
{
  reg u64[4] h g;

  g = #copy(gs);
  h = __mul4_rsr(fs, g);

  return h;
}

// ////////////////////////////////////////////////////////////////////////////

inline fn __mul4_a24_rs(stack u64[4] fs, inline u64 a24) -> reg u64[4]
{
  inline int i;
  reg bool cf;
  reg u64[4] h;
  reg u64 c r0 lo;

  c = a24;

  (h[1], h[0]) = #MULX(c, fs[0]);
  (h[2], lo)   = #MULX(c, fs[1]);

  cf, h[1] += lo;

  (h[3], lo)   = #MULX(c, fs[2]);

  cf, h[2] += lo + cf;

  (r0,   lo)   = #MULX(c, fs[3]);

  cf, h[3] += lo + cf;

     _, r0 += 0 + cf;

  _, _, _, _, _, r0 = #IMULri (r0, 38);

  cf, h[0] += r0;
  cf, h[1] += 0 + cf;
  cf, h[2] += 0 + cf;
  cf, h[3] += 0 + cf;

  _, c -= c - cf;

  c &= 38;
  h[0] += c;

  return h;
}

inline fn __mul4_a24_ss(stack u64[4] fs, inline u64 a24) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h;

  h = __mul4_a24_rs(fs, a24);
  hs = #copy(h);

  return hs;
}


inline fn __sqr4_rr(reg u64[4] f) -> reg u64[4]
{
  reg bool cf of;
  inline int i;
  reg u64[8] t;
  reg u64[4] h r;
  reg u64 z _38 fx;

  of, cf, _, _, _, z = #set0();

  // 0
  fx = f[0];

  (t[1], h[0]) = #MULX ( fx,   fx       ); // f0*f0
  (h[2], h[1]) = #MULX ( fx,   f[1]     ); // f0*f1

  (h[3], t[2]) = #MULX ( fx,   f[2]     ); // f0*f2
     cf, h[2]  = #ADCX ( h[2], t[2], cf );

  (r[0], t[3]) = #MULX ( fx,   f[3]     ); // f0*f3
     cf, h[3]  = #ADCX ( h[3], t[3], cf );

  // 1
  fx = f[1];

  (t[4], t[3]) = #MULX ( fx,   f[2]     ); // f1*f2

  of, h[3]     = #ADOX ( h[3], t[3], of );
  cf, r[0]     = #ADCX ( r[0], t[4], cf );

  (r[1], t[4]) = #MULX ( fx,   f[3]     ); // f1*f3
     of, r[0]  = #ADOX ( r[0], t[4], of );

  (t[3], t[2]) = #MULX ( fx,   fx       ); // f1*f1

  // 2
  fx = f[2];

  (r[2], t[5]) = #MULX ( fx,   f[3]     ); // f2*f3

   cf, r[1]    = #ADCX ( r[1], t[5], cf );
   of, r[1]    = #ADOX ( r[1], z,    of );

   cf, r[2]    = #ADCX ( r[2], z,    cf ); // cf = 0
   of, r[2]    = #ADOX ( r[2], z,    of ); // of = 0 ?? TODO: VERIFYME

  (t[5], t[4]) = #MULX ( fx,   fx       ); // f2*f2

  // 3
  fx = f[3];

  (r[3], t[6]) = #MULX ( fx,   fx       ); // f3*f3

  //
  cf, h[1] = #ADCX ( h[1], h[1], cf );
  of, h[1] = #ADOX ( h[1], t[1], of );

  cf, h[2] = #ADCX ( h[2], h[2], cf );
  of, h[2] = #ADOX ( h[2], t[2], of );

  cf, h[3] = #ADCX ( h[3], h[3], cf );
  of, h[3] = #ADOX ( h[3], t[3], of );

  cf, r[0] = #ADCX ( r[0], r[0], cf );
  of, r[0] = #ADOX ( r[0], t[4], of );

  cf, r[1] = #ADCX ( r[1], r[1], cf );
  of, r[1] = #ADOX ( r[1], t[5], of );

  cf, r[2] = #ADCX ( r[2], r[2], cf );
  of, r[2] = #ADOX ( r[2], t[6], of );

  cf, r[3] = #ADCX ( r[3], z,    cf ); // cf = 0
  of, r[3] = #ADOX ( r[3], z,    of ); // of = 0 ?? TODO: VERIFYME

  _38 = 38;
  h = __reduce4(h, r, _38, z, cf, of);

  return h;
}

fn _sqr4_rr(reg u64[4] f) -> reg u64[4]
{
  reg u64[4] h;
  h = __sqr4_rr(f);
  return h;
}

inline fn _sqr4_rr_(reg u64[4] _f) -> reg u64[4]
{
  reg u64[4] _h h f;

  f = #copy(_f);
  h = _sqr4_rr(f);
  _h = #copy(h);

  return _h;
}

inline fn __it_sqr4_x2(reg u64[4] f, reg u32 i) -> reg u64[4]
{
  reg bool zf;
  reg u64[4] h;
  stack u32 _i;

  while
  { _i = i;

    h = __sqr4_rr(f);
    f = __sqr4_rr(h);

    i = _i;
    _,_,_,zf,i = #DEC_32(i);
  } (!zf)

  return f;
}

fn _it_sqr4_x2(reg u64[4] f, reg u32 i) -> reg u64[4]
{
  f = __it_sqr4_x2(f, i);
  return f;
}

inline fn _it_sqr4_x2_(reg u64[4] _f, reg u32 i) -> reg u64[4]
{
  reg u64[4] f;
  f = #copy(_f);
  f = _it_sqr4_x2(f, i);
  return f;
}


inline fn __sqr4_ss(stack u64[4] fs) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] f h;

  f = #copy(fs);
  h = __sqr4_rr(f);
  hs = #copy(h);

  return hs;
}

inline fn __sqr4_sx(#mmx reg u64[4] fs) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] f h;

  f = #copy(fs);
  h = __sqr4_rr(f);
  hs = #copy(h);

  return hs;
}

inline fn __sqr4_sr(reg u64[4] f) -> stack u64[4]
{
  stack u64[4] hs;
  reg u64[4] h;

  h = __sqr4_rr(f);
  hs = #copy(h);

  return hs;
}

inline fn __sqr4_rs(stack u64[4] fs) -> reg u64[4]
{
  reg u64[4] f h;

  f = #copy(fs);
  h = __sqr4_rr(f);

  return h;
}


inline fn __invert4(reg u64[4] f) -> reg u64[4]
{
  reg u32 i;
  stack u64[4] fs t0s t1s t2s t3s;
  reg u64[4] t0  t1  t2  t3;

  fs = #copy(f);

  // z2 = z1^2^1
  t0  = _sqr4_rr_(f);
  t0s = #copy(t0);

  // z8 = z2^2^2
  t1  = _sqr4_rr_(t0);
  t1  = _sqr4_rr_(t1);

  // z9 = z1*z8
  t1  = _mul4_rsr_(fs,t1);
  t1s = #copy(t1);

  // z11 = z2*z9
  t0  = _mul4_rsr_(t0s,t1);
  t0s = #copy(t0);

  // z22 = z11^2^1
  t2 = _sqr4_rr_(t0);

  // z_5_0 = z9*z22
  t1  = _mul4_rsr_(t1s,t2);
  t1s = #copy(t1);

  // z_10_5 = z_5_0^2^5
  t2 = _sqr4_rr_(t1);
  i = 4/2;
  t2 = _it_sqr4_x2_(t2, i);
  t2s = #copy(t2);

  // z_10_0 = z_10_5*z_5_0
  t1  = _mul4_rsr_(t1s,t2);
  t1s = #copy(t1);

  // z_20_10 = z_10_0^2^10
  i = 10/2;
  t2 = _it_sqr4_x2_(t1, i);

  // z_20_0 = z_20_10*z_10_0
  t2  = _mul4_rsr_(t1s,t2);
  t2s = #copy(t2);

  // z_40_20 = z_20_0^2^20
  i = 20/2;
  t3 = _it_sqr4_x2_(t2, i);

  // z_40_0 = z_40_20*z_20_0
  t2  = _mul4_rsr_(t2s,t3);

  // z_50_10 = z_40_0^2^10
  i = 10/2;
  t2 = _it_sqr4_x2_(t2, i);

  // z_50_0 = z_50_10*z_10_0
  t1  = _mul4_rsr_(t1s,t2);
  t1s = #copy(t1);

  // z_100_50 = z_50_0^2^50
  i = 50/2;
  t2 = _it_sqr4_x2_(t1, i);

  // z_100_0 = z_100_50*z_50_0
  t2  = _mul4_rsr_(t1s,t2);
  t2s = #copy(t2);

  // z_200_100 = z_100_0^2^100
  i = 100/2;
  t3 = _it_sqr4_x2_(t2, i);

  // z_200_0 = z_200_100*z_100_0
  t2  = _mul4_rsr_(t2s,t3);

  // z_250_50 = z_200_0^2^50
  i = 50/2;
  t2 = _it_sqr4_x2_(t2, i);

  // z_250_0 = z_250_50*z_50_0
  t1  = _mul4_rsr_(t1s,t2);

  // z_255_5 = z_250_0^2^5
  i = 4/2;
  t1 = _it_sqr4_x2_(t1, i);
  t1 = _sqr4_rr_(t1);

  // z_255_21 = z_255_5*z11
  t1 = _mul4_rsr_(t0s,t1);

  return t1;
}


inline fn __add_and_double4(
  stack u64[4] init,
  #mmx reg u64[4] x2,
  reg      u64[4] z2r,
  stack    u64[4] x3,
  stack    u64[4] z3)
  ->
  #mmx reg u64[4],
  reg      u64[4],
  stack    u64[4],
  stack    u64[4]
{
  stack u64[4] z2 t0 t1 t2;
  reg u64[4] t1r;

  t0  = __sub4_sxr(x2, z2r);
  x2  = __add4_xxr(x2, z2r);

  t1  = __sub4_sss(x3, z3);
  z2  = __add4_sss(x3, z3);

  z3  = __mul4_sxs(x2, t1);
  z2  = __mul4_sss(z2, t0);

  t2  = __sqr4_sx(x2);
  t1r = __sqr4_rs(t0);

  x3  = __add4_sss(z3, z2);
  z2  = __sub4_sss(z3, z2);

  t0  = __sub4_ssr(t2, t1r);
  x2  = __mul4_xsr(t2, t1r);

  z2  = __sqr4_ss(z2);
  z3  = __mul4_a24_ss(t0, 121665);
  x3  = __sqr4_ss(x3);

  t2  = __add4_sss(t2, z3);
  z3  = __mul4_sss(init, z2);
  z2r = __mul4_rss(t0, t2);

  return x2, z2r, x3, z3;
}

inline fn __montgomery_ladder_step4(
  stack    u8[32] k,
  stack    u64[4] init,
  #mmx reg u64[4] x2,
  reg      u64[4] z2r,
  stack    u64[4] x3,
  stack    u64[4] z3,
  stack    u64    swapped,
  reg      u64    ctr)
  ->
  #mmx reg u64[4],
  reg      u64[4],
  stack    u64[4],
  stack    u64[4],
  stack    u64
{
  reg u64 toswap bit;

  bit = __ith_bit(k, ctr);

  toswap  = swapped;
  toswap ^= bit;

  x2, z2r, x3, z3 = __cswap4_xrss(x2, z2r, x3, z3, toswap);
  swapped = bit;

  x2, z2r, x3, z3 = __add_and_double4(init, x2, z2r, x3, z3);

  return x2, z2r, x3, z3, swapped;
}


inline fn __montgomery_ladder4(
  reg u64[4] u,
  stack u8[32] k)
  ->
  #mmx reg u64[4],
  reg      u64[4]
{
  stack u64[4] us x3 z3;
  #mmx reg u64[4] x2;
  reg u64[4] z2r;
  stack u64 ctrs swapped;
  reg u64 ctr;

  (x2,z2r,x3,z3) = __init_points4(u); 
  us = #copy(u);

  ctr = 255;
  swapped = 0;

  while
  {
    ctr -= 1;
    ctrs = ctr;

    (x2, z2r, x3, z3, swapped) = 
      __montgomery_ladder_step4(k, us, x2, z2r, x3, z3, swapped, ctr);

    ctr = ctrs;
  } (ctr > 0)

  return x2, z2r;
}

inline fn __encode_point4(#mmx reg u64[4] x2, reg u64[4] z2r) -> reg u64[4]
{
  reg u64[4] r;

  z2r = __invert4(z2r);
  r = __mul4_rxr(x2, z2r);
  r = __tobytes4(r);

  return r;
}

inline fn __curve25519_internal_mulx(stack u8[32] k, reg u64[4] u) -> reg u64[4]
{
  #mmx reg u64[4] x2;
  reg u64[4] z2r r;

  (x2,z2r) = __montgomery_ladder4(u, k);
  r = __encode_point4(x2,z2r);

  return r;
}

inline fn __curve25519_mulx(reg u64[4] _k _u) -> reg u64[4]
{
  stack u8[32] k;
  reg u64[4] u r;

  k = __decode_scalar(_k);
  u = __decode_u_coordinate4(_u);
  r = __curve25519_internal_mulx(k, u);

  return r;
}

inline fn __curve25519_mulx_base(reg u64[4] _k) -> reg u64[4]
{
  stack u8[32] k;
  reg u64[4] u r;

  k = __decode_scalar(_k);
  u = __decode_u_coordinate_base4();
  r = __curve25519_internal_mulx(k, u);

  return r;
}


export fn jade_scalarmult_curve25519_amd64_mulx(reg u64 qp np pp) -> reg u64
{
  reg u64 r;
  stack u64 qps;
  reg u64[4] q n p;

  qps = qp;
  n   = __load4(np);
  p   = __load4(pp);

  q = __curve25519_mulx(n, p);

  qp = qps;
  __store4(qp, q);

  ?{}, r = #set0();
  return r;
}

export fn jade_scalarmult_curve25519_amd64_mulx_base(reg u64 qp np) -> reg u64
{
  reg u64 r;
  stack u64 qps;
  reg u64[4] q n;

  qps = qp;
  n   = __load4(np);

  q = __curve25519_mulx_base(n);

  qp = qps;
  __store4(qp, q);

  ?{}, r = #set0();
  return r;
}

